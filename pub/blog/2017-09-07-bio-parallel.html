<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8" />
  <title>GSoC 2017: Parallelism in BioJulia</title>
  <meta name="author" content="Jeff Bezanson, Stefan Karpinski, Viral Shah, Alan Edelman, et al." />
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="Official website for the Julia programming language. Join the Julia community today.">

  <meta property="og:title" content="The Julia Language"/>
  <meta property="og:image" content="http://www.julialang.org/images/julia-open-graph.png"/>
  <meta property="og:description" content="Official website for the Julia programming language"/>

  
   <!-- Syntax highlighting via Prism, note: restricted langs -->
<link rel="stylesheet" href="/libs/highlight/github.min.css">
   
  

  <link href="https://fonts.googleapis.com/css?family=Roboto:400,400i,500,500i,700,700i" rel="stylesheet">
  <link rel="stylesheet" href="/assets/v2/css/bootstrap.min.css" />
  <link rel="stylesheet" href="/assets/v2/css/app.css" />
  <link rel="stylesheet" href="/assets/v2/css/fonts.css" />
  <link rel="stylesheet" href="/assets/v2/css/highlight/github.css" />

  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-28835595-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-28835595-1');
</script>

</head>

<body>

<div class="jd-content">
<p>In this summer, I have worked on a project to develop tools that make BioJulia run faster. As an outcome, Automa.jl now generates more efficient code to parse text files, ConcurrentCalls.jl runs multiple tasks in parallel, and simple and efficient interfaces to various compression formats are provided in TranscodingStreams.jl.</p>
<h2 id="instruction-level_parallelism"><a href="/pub/blog/2017-09-07-bio-parallel.html#instruction-level_parallelism">Instruction-level parallelism</a></h2>
<p>Instruction-level parallelism is a technique to run multiple instructions simultaneously on a CPU core. This may sound odd but actually it is possible because CPU instructions are executed in multiple stages such as fetch, decode, execute, and so on. This is called <a href="https://en.wikipedia.org/wiki/Instruction_pipelining">instruction pipelining</a> and modern processors can execute these stages in parallel and hence processing throughput may be boosted by utilizing it.</p>
<p>I implemented automatic loop unrolling in <a href="https://github.com/BioJulia/Automa.jl">Automa.jl</a>, which is a package to generate finite state machine &#40;FSM&#41; from regular expressions. We use it to generate high-performance parsers for various file formats used in bioinformatics.  The loop unrolling factor can be specified as an argument of <a href="http://biojulia.net/Automa.jl/latest/references.html#Automa.CodeGenContext"><code>Automa.CodeGenContext</code></a>. For example, you can specify the value 8 in this way: <code>context &#61;
Automa.CodeGenContext&#40;loopunroll&#61;8&#41;</code> and that is all. The code generator of Automa.jl will automatically unroll loops found in an FSM.</p>
<p>Automa.jl works by incrementally increasing a reading position variable and reading data byte by byte from a buffer. This is difficult to unroll because the position variable creates a critical path of data dependencies. So, Automa.jl unrolls particular nodes in an FSM that have a self edge and have no actions within state transition.</p>
<p>Let&#39;s see the improvement of performance. <a href="https://en.wikipedia.org/wiki/FASTA_format">FASTA</a> and <a href="https://en.wikipedia.org/wiki/FASTQ_format">FASTQ</a> are one of the most common file formats to store biological sequences. I benchmarked parsing throughput in these two formats. The throughput improved as the loop unrolling factor was increased and saturated around factor &#61; 10.</p>
<p><img src="/assets/images/blog/2017-09-07-bio-parallel/fasta-fastq-benchmarks.png" alt="FASTA-FASTQ benchmarks" /></p>
<p>Unrolled parsing achieved about 1.3 times speedup in both cases.  This benchmark does not include I/O operations but other operations that are required to convert byte data to our data type are included. The improvement may not look surprising, however, we should note that it is achieved almost for free. There is no need to use more CPU cores.</p>
<h2 id="task-level_parallelism"><a href="/pub/blog/2017-09-07-bio-parallel.html#task-level_parallelism">Task-level parallelism</a></h2>
<p><a href="https://github.com/bicycle1885/ConcurrentCalls.jl">ConcurrentCalls.jl</a> is a package that makes function calls &#40;or tasks&#41; run concurrently. It exports a macro <code>@cc</code> that transforms Julia code to code that calls functions on remote processes.  This is a conceptual example of running tasks in parallel:</p>
<pre><code class="language-julia">addprocs(2)
using ConcurrentCalls

function multitask()
    # Define some time-consuming (say >10ms) task(s).
    function sum(x, y)
        sleep(2)
        return x + y
    end
    function prod(x, y)
        sleep(1)
        return x * y
    end

    # Call functions concurrently using multiple processes.
    @cc begin
        x = sum(1, 2)       # =>  3
        y = sum(3, 4)       # =>  7
        prod(x, sum(y, 1))  # => 24
    end
end

multitask()  # => 24</code></pre>
<p>In the example above, <code>x &#61; sum&#40;1, 2&#41;</code> and <code>y &#61; sum&#40;3, 4&#41;</code> will be executed in parallel on different processes. These function calls are arranged by a scheduler of ConcurrentCalls.jl and each taks is assigned to a worker process based on some heuristics. The third line inside the <code>@cc</code> macro has two function calls. Each of them will also be assigned to a worker but it never starts until the first two finish. Dependencies of tasks are handled by the scheduler and a task will not be executed until all of its arguments are finished and results are available.</p>
<p>Execution of tasks are defined in an imperative way and so its semantics would be apparent from the code. Data dependencies are naturally expressed by arguments passed to functions.  The code below shows three examples that use a for loop to describe a job:</p>
<pre><code class="language-julia"># independent tasks
@cc begin
    for i in 1:100
        task()
    end
end

# sequential taks (not parallelizable)
@cc begin
    a = task1()
    for i in 1:100
        a = task2(a)
    end
end

# biparallel tasks
@cc begin
    a = task1()
    b = task2()
    for i in 1:100
        a = task3(a)
        b = task4(b)
    end
end</code></pre>
<p>This package is still at a very early stage of development but some simple subset of Julia code can be executed in parallel. See the <a href="https://github.com/bicycle1885/ConcurrentCalls.jl#usage">README</a> page of ConcurrentCalls.jl for more examples and some caveats.</p>
<h2 id="new_io_apis"><a href="/pub/blog/2017-09-07-bio-parallel.html#new_io_apis">New I/O APIs</a></h2>
<p>A difficulty of parallelizing data processing in bioinformatics is that input files are often compressed. The most common compression format, gzip, does not support either parallel decompression or splitting data into smaller chunks. Some special file formats &#40;<a href="https://github.com/BioJulia/BGZFStreams.jl">BGZF</a> for example&#41; can support parallel decompression and chunking but gzip is still slow.</p>
<p>A recent compression algorithm known as <a href="http://facebook.github.io/zstd/">Zstandard</a> &#40;or Zstd&#41; is much faster than gzip while keeping the compression ratio at the same level of gzip. Moreover, it started to implement an experimental support of <a href="https://github.com/facebook/zstd/blob/dev/contrib/seekable_format/zstd_seekable_compression_format.md">seekable compression format</a>, in which data are split into frames and each of which are compressed independently. Tables to seek to a specific position are stored in <em>skippable</em> frames and hence it can support parallel processing and chunking.</p>
<p>To support this feature, I implemented an interface package to Zstd, which is already available as <a href="https://github.com/bicycle1885/CodecZstd.jl">CodecZstd.jl</a>. While it does not yet support the seekable format, we can enjoy the performance of Zstd immediately. Also, this package is built on top of <a href="https://github.com/bicycle1885/TranscodingStreams.jl">TranscodingStreams.jl</a>, which offers simple and consistent APIs for many data formats. Currently, <a href="https://github.com/bicycle1885/CodecZlib.jl">gzip &#40;zlib&#41;</a>, <a href="https://github.com/bicycle1885/CodecBzip2.jl">bzip2</a>, <a href="https://github.com/bicycle1885/CodecXz.jl">xz</a>, and <a href="https://github.com/bicycle1885/CodecZstd.jl">zstd</a> are supported. These packages are replacements of <a href="https://github.com/BioJulia/Libz.jl">Libz.jl</a> and <a href="https://github.com/BioJulia/BufferedStreams.jl">BufferedStreams.jl</a> I maintain.</p>
<h2 id="plans"><a href="/pub/blog/2017-09-07-bio-parallel.html#plans">Plans</a></h2>
<p>Speeding up programs never ends. I still have some pending pull requests that are required to work well with these tools &#40;<a href="https://github.com/BioJulia/BioCore.jl/pull/7">https://github.com/BioJulia/BioCore.jl/pull/7</a>, <a href="https://github.com/BioJulia/BioAlignments.jl/pull/4">https://github.com/BioJulia/BioAlignments.jl/pull/4</a>, <a href="https://github.com/BioJulia/BioSequences.jl/pull/25">https://github.com/BioJulia/BioSequences.jl/pull/25</a>&#41;. ConcurrentCalls.jl lacks examples, tests, benchmarks, and many features to be used in real work. CodecZstd.jl will support the seekable format once it gets stable. I really welcome feedbacks of these designs and ideas to improve them further.</p>
<h2 id="acknowledgments"><a href="/pub/blog/2017-09-07-bio-parallel.html#acknowledgments">Acknowledgments</a></h2>
<p>I appreciate contributions of my mentor Shashi Gowda and other members of the Julia community.</p>

<head>
  <meta name="description" content="We thank our contributors, donators, and Fastly for their support in keeping the Julia Language going. Donate here to help pay for Julia's needs."/>
</head>

<footer class="container-fluid footer-copy">
    <div class="container">
      <div class="row">
        <div class="col-md-10 py-2">
          <p>
            We thank <a style="color: #7a95dd" href="https://www.fastly.com">Fastly</a> for their generous infrastructure support. Donations help pay for community resources such as CI, Discourse, workshops, travel, JuliaCon, and other such needs.
          </p>
          <p>
            ©2020-01-19 JuliaLang.org contributors. The website content uses the <a style="color: #7a95dd" href="https://github.com/JuliaLang/www.julialang.org/blob/master/LICENSE.md">MIT license</a>.
          </p>
        </div>
        <div class="col-md-2 py-2">
          <a class="btn btn-success" href="https://numfocus.org/donate-to-julia">Donate</a>
        </div>
      </div>
    </div>
</footer>

</div>
    
    
        <script src="/libs/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: '    '});</script>

    
    <script src="/assets/v2/js/jquery.min.js"></script>
<script src="/assets/v2/js/bootstrap.min.js"></script>
<script src="/assets/v2/js/platform.js"></script>
<script src="/assets/v2/js/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
<script async defer src="https://buttons.github.io/buttons.js"></script>

  </body>
</html>
